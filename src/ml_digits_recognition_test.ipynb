{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms.functional as fn\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torchvision.utils import make_grid\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from custom_neural_network import NeuralNetwork\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "os.chdir(os.path.abspath(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "NeuralNetwork(\n  (cnn1): Sequential(\n    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Flatten(start_dim=1, end_dim=-1)\n    (6): Linear(in_features=16, out_features=120, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=120, out_features=84, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=84, out_features=10, bias=True)\n    (11): LogSoftmax(dim=1)\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load('model_precise.pt'))\n",
    "model.eval()\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def cnn_classifier(x):\n",
    "    return torch.argmax(model(x)).item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test with images created on the fly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Image.open('Custom test inputs/9e.png') as img:\n",
    "    test_input = ToTensor()(img)\n",
    "    if test_input.shape[0] == 4:\n",
    "        test_input = test_input[None, 3, :, :]\n",
    "test_input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 96, 96])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=96x96>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAAAAADH8yjkAAADxElEQVR4nO1ZW0hUURTdmhPOlGmoqGVZCVH2QDLJsrIsSCvMpCfUh4ZkhUFZGUJgEn0FQdGvGlFQChlUH71UDDQqKAwfEDFhWSmYaT7yMaeP2duZuTN35tzH/nP97Ln37LPW3fvMPufccwGmYSqCI0O1dgmS9duWAunpoTbHl9a2to6Pk1p1AiH8lXBHb3WaufwL3wslWg5ZzOMPeuHFL4T4eT1jhkkCR3zxCyFEb1Wu1QyB12oCQoi+a/MM8y/xwy+EGCw1mqmj/gWEeBqp3jlYJgK0qn/+7KZwQwIRaCsq/qh4LK8JkeBRRSVmogCs2ZduN333laUCIwLVSFKI14vK7F4CdrWBlkkRJSYCrf1qYl69wich2YAADbLrIScfZq5+4Om00oDAOrRf3W+2HjzrcL+eI0GkgihM83iEomHfiNsgnFHpLRFBLFp7v6KhdrdwXagViYTAbLRKfoCXz12/B/QL2NBGek8I1a6f3vLSSKM0dyYqm6z9U2OwVL9AnINIes9FKdruUVOf7OLuC27LwejdZI+mfdTwxAA/bBpznxQep7g1raK7ZUYEoMhj2nE82jqVjzpzBKBk0nNqayt2LgBTGRLH1bpKjk3OHcVUMPTg8+CvicqphaagSsdzu2NZu9cM7YHzah1lJjsAgI7Uiz3+2mdqelzfsOW3qEdwzAQBAMhoUBPYZY4AQGa9b4E8swQAVtwa8CFwwTwBgLCiD14CxWrOOueohC2xlpiYufDtgNXJkPdQH1EgbKYI1vDwQy3yd8vWk0YsGEeBGzz8cIUylMzDH0Lb1AYefjhMAezl4Q+icugy62VQgSwK4DIPP9DL+Vg8D38qBVDJww81yO9I4uGPn0CBOh5+KKEMbWASoPORRib+RApgP5PASeQfCHAaonua3Y62bkQvg39YfmMEh3j4YSfyT0YzCVCVvWPiX0JVVsokcJOmiUU8/HNo78VVZaepyvYwCTQifyfTbmXWPxQ4xcMP2cj/Nyywr64YN6JtHGQSoJNx5bGXWbAOY4rSmQRouzJmC+yrK0VZaJuHmQWe6egrgxgq45TAvrqQh/w9UtHrSNF6tA0Ov276BTLQNmvvKoVoWmvWMgnkI3+/3EuB9hTtQNto+sc6J4J+YAQmna94YTFVgeTHJ80pmo+2s5tJgB68XdJfswC9j3VxCdBq9kVrR0nMpcUml0ngBPJPcG1636DAKyb+HKqCwsC+Tmgc5LhRpx26r62fPJLeCiGEMHpS7QeW8jHGDQsAAKR8EmwJciK0XPkpZxpG8B/2ka84PNICdQAAAABJRU5ErkJggg==\n"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToPILImage()(test_input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(3), tensor(92), tensor(34), tensor(72))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero = (test_input != 0).nonzero()\n",
    "h_min = non_zero[:, 1].min()\n",
    "h_max = non_zero[:, 1].max()\n",
    "w_min = non_zero[:, 2].min()\n",
    "w_max = non_zero[:, 2].max()\n",
    "h_min, h_max, w_min, w_max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_d = w_max - w_min\n",
    "h_d = h_max - h_min\n",
    "h_avg = h_min + h_d / 2\n",
    "w_avg = w_min + w_d / 2\n",
    "h_tot = test_input.shape[1]\n",
    "w_tot = test_input.shape[2]\n",
    "test_input_nn = test_input[:, max(0, int(h_avg-w_d/2)):min(h_tot, int(h_avg+w_d/2)), w_min:w_max] if h_max - h_min < w_max - w_min else test_input[:, h_min:h_max, max(0, int(w_avg-h_d/2)):min(w_tot, int(w_avg+h_d/2))]\n",
    "test_input_nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 89, 88])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_nn.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=88x89>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABZCAAAAACforxNAAADq0lEQVR4nLWZa0hUURDHZ8sNd8sXKmpZmkKUPZA2ybKyLEgrzBYrg/qgIVlhUFaGEJREn4Kg6KsaUZAKGlQfeqiLgUYFheEDQgzLSsFM89Hq7unDzuzj3r3v4//L7N0z89u5c++Zc89dADVaEB2qys9PJqXx3TbIygq1uvu7urt7P7m08qUU0cL8NVKXyYe74gMTqrPIbJxreiXiMsZ+3s5eaBB8PBiXMcZGagssRsBvpMCMsdFbS3VzU2S4jLGJSr0VOSEPZux5tHTwArmM0UrevHntEbrAkWirq/9IeKxpCJGJl1QNnnEJWPKu3m//HqwaJXrAdRhcisfJVQMi8IDUBZQrBRUgEu3AzVR7q8AnKV0HmC6eLylXU86G+kCndTrAm9F+9f+y6+gFt/9xuAxAQjFYxtlIwUDhtF+Rz0tEy2Qcj3ZgTDDQeID5DqRuchnwErRCLsDrl77P49rBVrTR4olb5/so/llFZVIZ+1KFQ5Yxb41XaQcnuCl45GKMYOwRDY0qLZrB5NeOZx6mBwwV0sAzHVzY7vSfvE9tfkPr6dsqPWAoC2gL7ie7vOfdbAwMFa7AltNd7mnA3kqwU1KhCrXPfyCYspP1XyZ+zdV4G3xJrb6UYXWPqFMG6JJUoFwTAgDozbgyLDe+SFe6HlmLO6UzPmkADADZbVLg/cbAADmtwcF2o2CAtffGg4AvGwcDhJV9FIHLpZw19pCknfHmuLgo+HbE4om0NxnKVaQdlPFGvlxoRO6Q0jzQqOWzCL7Dlws3qBLpfLkh9BjXxpcLxyjhQ3y5JrqdB41ucgTKpYSv8+UCbSqdiXy5GZRwDV8uNCDXncaXmziH4Ga+XKigSmzlDKZ9u4MzN5USPswZfAa54wq7dM1tbw/a5mkdWcnI/BszLuLLhX3IdcVyBtPseM+Zm0Kzo5Iz+C5N52S+3HB6ZuE9O87R7DjIGexAbh/nVX/xPwSf5cuFPOT+DVP21XRO29A6JjiD6Y2p8DWLUVmmsBRZnMG07Dutyr6aSpGLtmNqnsAvNMSoURxNO5uyrybZkTus6iw1lGIL2ja3rJt2cDbaDvUhqhRLPX4TZ3AxcsfUPRSrL8VetA5uf7J4ZPqBGRvc74u0ku5ilX8mqC7FMrR9Q5zBlGiPSn/VYNpvDPIG0+rRrzZApaKoyRdwBp9G7hzvh8G3CG7hzM2nu7hU2dcjlRcvYcZjJx/rSUtOae8YY4zpfZMpI/M15zws/AAAYPvMNBTiP/zwrpxe2aHSAAAAAElFTkSuQmCC\n"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToPILImage()(test_input_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=20x20>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAAAAACo4kLRAAAAjklEQVR4nH2OMRLBYBhEn0woFNRKhcpddBoHUaiVzuMA3EBGpTAK4wCZ0eTnKZD4k4ytdt7st/vBW4dwXVNTpqqjCOrirDqNIbDULIYdoHD/C1dawNF5VDoJqs4ASD7wlPZzwPpb8GhhXVtgcNCEZTCp2JhtM3hvacTn11XnQy7N4Mben+1ovVJautuutC87Kz1hxqHTiQAAAABJRU5ErkJggg==\n"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_nn = fn.resize(test_input_nn, size=[20,20])\n",
    "ToPILImage()(test_input_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 20, 20])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_nn.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlklEQVR4nMXNMQ4BURCH8c9mKRTUSoXKXXQaB1Golc7jANzARqUQhTjAJppdPp3sS957JdPN/OY/A/+tU3vfpqxS1UkUdXVVnccRWGsVxx7QeIzhRhs4u4w+nbWqLr6DooOXclgDRpMAvDLWN4OtozQGwSK0Kft08Jn5iO9uF54dc0sHdw4yV8OXRWINgDLoHofc7k/qA1gWPWE9XcZ1AAAAAElFTkSuQmCC\n"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_nn = fn.pad(test_input_nn, padding=[4,4])\n",
    "ToPILImage()(test_input_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 28, 28])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_nn.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Neural network classification: {cnn_classifier(test_input_nn)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification of all the files in the test folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_test_input_from_pil(img):\n",
    "    test_input = ToTensor()(img)\n",
    "    if test_input.shape[0] == 4:\n",
    "        test_input = test_input[None, 3, :, :]\n",
    "    non_zero = (test_input != 0).nonzero()\n",
    "    h_min = non_zero[:, 1].min()\n",
    "    h_max = non_zero[:, 1].max()\n",
    "    w_min = non_zero[:, 2].min()\n",
    "    w_max = non_zero[:, 2].max()\n",
    "    w_d = w_max - w_min\n",
    "    h_d = h_max - h_min\n",
    "    h_avg = h_min + h_d / 2\n",
    "    w_avg = w_min + w_d / 2\n",
    "    h_tot = test_input.shape[1]\n",
    "    w_tot = test_input.shape[2]\n",
    "    test_input_nn = test_input[:, max(0, int(h_avg-w_d/2)):min(h_tot, int(h_avg+w_d/2)), w_min:w_max] if h_max - h_min < w_max - w_min else test_input[:, h_min:h_max, max(0, int(w_avg-h_d/2)):min(w_tot, int(w_avg+h_d/2))]\n",
    "    test_input_nn = fn.resize(test_input_nn, size=[20, 20])\n",
    "    test_input_nn = fn.pad(test_input_nn, padding=[4, 4])\n",
    "    return test_input_nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAARElEQVR4nGNgGFDw//+7ef/+/8cqhYWFXx02Afx6SQD/sXKZ8GkZCEkooJa30c1B4duT5ACEyG+S9EGE//euoVpUkgsAKkgY9DxwUsAAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `0.png`: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAn0lEQVR4nMWQMQrCQBBFPxFsrLSNYOsVtBCsPUBqwU4v4WU8hRcQ25SCJ7A0VeRZuE7i7phSf7Nv5+3AzEp/zhQ4f3FzALh57kpInToA1juAvesk6R7OyF0Mhx+uAjaB67gV2L6578hR+/KCzEoDZzt73OvqnHV1GhfOQJMWn2K5CJhsorKp4H9fmUm547SkySGZd2zu6K2zAuDhqR/mCaN8ix4j1tE8AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `0b.png`: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAaElEQVR4nGNgGHDw/wMyjxFVDlWACVluP24jLf7/Z/g/EauU5///MgwM/3FoZIVaihugSjLhUIVF8ileU78TbSUpdg52SRYGBgYGBtFXDAwMt34wMFz6z8DAwKAHjXEoheZ71PRBVwAA8ukWny72+k0AAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `1.png`: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAj0lEQVR4nMWOoRHCQBREN0SCRWIzuAwWjQhdICgjFaQELGUwg6aAmCjKAEMekn/HbCSs2313+1f6vxbrCfjkYNkG6Bx8AXvDGuDhPgJUH1ukME1mkR0lta51AObBx9pizIJYu5V0ca09kAyMJtuarc0V4E7Syb27AaskCTe+TobapaS7az0Dtd1WXrHsd3oDS5orvk7R3BYAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `1b.png`: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAb0lEQVR4nM3QMQ5AQBCF4aVXaXQ655Eoncg1HEOncwyVSmhE6Vdsgqx9W4rpZr43yWSM+UHNNNI2QNmCxAoUTgAcXrRbI3QCW7ND7cXCRtJrFLmR5yj23/0bzELZHgaJK5QSgTyEyd057+P90I/rBMwtQD3rlCNLAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `1c.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAb0lEQVR4nGNgGEjA9u//////X2OT4vgPA9hkYYLYZdFVMTAwMGHKKpOtk0aSlvgkn+ExC59rOfA5AnvwLd/JxMDAUPUfi9Zz0BjBqvH/ewYGJpwxxonbQob//93+/8cZ4f////8fw8CgjTM10AkAAGQ4Qo6dtHjUAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `2.png`: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAc0lEQVR4nGNgGEDwHwp0kcQY4ZIMDH++r/6VgSSEzQgxvObDmUz43EG+JBY7BbAKh35qRHEPqh4ISMcquer///9T/P//L8Nj6QccBkONhzGweoWVTJ1r8FqJx0FIcvCY1Wdg4FfQyuDHGtmwZJKAz0Y6AADjrzVqYL+cbgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `3.png`: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAWUlEQVR4nGNgGECg/x/GisSUZIFL/seUZMAiyYTPKrhkAj5V/2Px2KmExU5GTAchiWGxAK4Mr2uxAE1soQA3dhI+SQl8dorgk2TBJ/mFKElsDoKziIuywQIAXBEUQ/un45UAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `4.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAaElEQVR4nGNgGDjwXwSLIBNcFkLewir5E0JtxCr5B0I9xirJhsZH4TBDKG6sku8hlBBWyXsQ6jcDA4PEB6gYI0zyP7IWRgZs4H8NVmOhgBefJCc+SYYBkPyKT/IzPkkOfJI8+NxADwAAQH4QHawhkdAAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `4b.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzUlEQVR4nMWPMWoCURRFT8SQCBKGIFhaWwiCpQnYZwkuIWVWkNp9ZAdpbG2yjTQSSKEoEmXIHIv5Y0YnP6W51X2c9y7vwj/pevX6NAi+vVi6KsNEzYJ/Vj/KsKXugs/UySncBq96EXwN4Bu4zOcrAAOsA2yLLZgBab/RfSmSaKi2SDrNYWqu5HD5BfBZrZinzavVf2DvmKTr93F5cepBj9X8XJnaj0HV2slDhW4AsggcEnr9Bu+Atxi8BzZ//fMQYbeqpfkodgQsY6ln0h6RzVobpX0fAwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `4c.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAo0lEQVR4nMWQsQ3CMBBFnxOQQIGOnhEo6JiBMrMg1mABVqBmGWjoaChAikiUTwG2sYgtUSB+dXdP/nf+8C+p3S19V5UmgJJ8d5dORQJqBJBFFk1iUMAl9RKAnqvW+/ZVZUANYJxRqPHV2Tbdtk+4+pg33pbpIj/ObC6bHIZV5MjaRtL1FQMM3mwDyc6TIXwLC+Acg33gEINz4BbbtJVUpk75qR4DdCzTywCMvwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `4d.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkUlEQVR4nGNgGBxA88lWGyTu////kXimMC4TFp1qqFxUnYf///+HKqmCZCeGsc4IyZ8wBlzyBkKSEUPyPpIlqA769x8JrPwPsxNixG8WdO8wIozVR5dDBSwMHDDAEIDqbVSw////PFTXIoE/GA5GAp/+/xfHKfn//38OfJKMuOwUZIDZiUWSD87CIvkNp330AACwb0AAyglQ0AAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `4e.png`: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABOElEQVR4nGNgoD9gROFwcjBouAv+Xlrv+5OTgYGBBSYhyqVmIqevysDM+uuRkuvH6wxIkspdhhzsLOwsjAz/H876tvXlW2TJDyxinAwMDK8e8yg8WPb//5+/KJLL3v200n6zeCm3FedHDJcJ6qjW3NvhyMgiKgcXgzvo/ad/9z4ICf3/8xqhgQnO+vv/1FFhK0lk01iQ2PdWyNl/PXfrGvYQ4Yw6eO/4BEMubDoZvu9hCjOX51557BtWvTz2PeferPbDbjADi0zF788bRdBdy8DAwMDALibCyMAmIYTFTjYRTStTDcbvd25jSDLzq3l4anL/eXvr/H80y5g5tbL3fvjz4/WZLkM0KUYhTd8N7//+fHe+3YARVYqFR37G5S9//3y/3KTHiu5+88W3f/z9+/f7FhcMKboDAEjcaIEmfY7TAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `5.png`: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAY0lEQVR4nGNgGEAg/R8BYGIsMAYzAyOGBiZ8phEnaYFP1Z7/mGJwnVwf8eiUxaITDv6b45Hs/f//////hihiaD7/jyGCAtbhs5vhvzReWTiLCmFLsiQmQPIKC4YYG2lmURsAABT8HPHjqlGuAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `5b.png`: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAdklEQVR4nM2PwQ1AQBBFP0GiAScSDbhqSgsuetCBQvauAh3ogcNzIZHszh7FP03mzZ8/I/1Ck3uqzGMI0wdJhNl5f2ILA1BZRtgw7DBLSoJ0v5s5feSclzX1phpFYBnIrCm8te/QUZJc+JcDaGENQukEOoN9pQu8QjxZy1KvJQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `6.png`: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAb0lEQVR4nGNgGEDAqiTIILT4//9b//9jSor///////9020cMWCThAEmOCUPuI3EaMeUqiNWIZuf/BUTbiKzz////DP////+/AZs2eYb/6xkYOCQFiTEVMxBwSr77jUcleugQbezfzySYSoJrBwMAAG3FJu30i+QgAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `7.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAApElEQVR4nL2QMQrCQBBFf1LFQiy8gI2NjVgK3kFBPIdH8RS2nsFKELEQUlpGsFZEAkmehbC4y45lfrPLvH0z7EjtJ/kedar3tuw9jqdh3h8cbt6bOX78DgFcenAxqmzTZQ2QxlkBNIZX2j0zgCaJsgnAM+51AfbGPICVwS7AzGACzhYb23uRXnAPa25RHWkTQvdjfu6hOTXnSdpBbcIr5P/k1vIBQmFudh/dJ6kAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `7b.png`: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiklEQVR4nL2SwRGCMBREHzjC0aEDR1uiAO4WYAt2YwW0YTPOuB4ikB8Wj+zlJ//Nbn4ygf1VzSvFbdBJcJE8VA/w1GBh+6sPA99Tok3WNdXG088fK2lW3SzkKDFmxuLWCp16ZT/7VDoJ5J/wLoDDxrSh2DN5+VcoqnMuCrDMy2GVqLLG2rrxV/bRFwzJKePszOMYAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `8.png`: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAbElEQVR4nGNgoD9gROb8R+OjyAmz/f8fh0uSgYGB4f9qPJJQkoGBgYGBCVnWEJ/r/v//////f0ec8gqycavgHBY0yQcMfB+w28nAwMDAoH8Bj+RDWXyuUscniWBiGsswlCSRBZCSxX8MkYEAACj7F+m6nZLKAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `9.png`: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAaUlEQVR4nMXQsQmAMBSE4T9iIYIjuJOli7mHrdMI2jmBCHJWomg40uXK93F5j0DeDJIkRa3bAIij+GKRulMAmp5B+cIgICxxJAA0bufqcHTYxm69M7tm7dD+0Jn47D+Ha+6u2RurXDF3LhfwFnoCmpH0AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `9b.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nMWPPQrCQBSEZxfSi2Arwco7WNhqYeEBPErwRN7DU3gCG8FGkHwWSdx98a2lTjfzMe9H+q+aG9cSewJwd9mBXjMHAlNtAMIQhQQ70wYR+yiO+opZwcBHVTp2y1sOrQdWu+U1AKfS7JU/tBMwTy6MoEnsnzvpnFnbtEXbnBRvkdTCPvf5FD4PTDrCwgRmJ8vLt60/0Qs0VkjZkTKy1wAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `9c.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiklEQVR4nMXOMQqDQBSE4WEhnaTxNDmEnafIIQQLT+EZcgkb+7S5QCAEIZUQ3D+FIkre2zKZcj9m3kr/zZ149ewJAJWJLBlsrHWKwPoStnxQH746c95AK5hMfcw3bZQuQPRQEtxcO28+axRfrgXIXOzTq10Kd0d21vg1aSSmVkvXjpD7zSKx+qN8AKMVS5RD90HBAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `9d.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlklEQVR4nMXNMQ4BURCH8c9mKRTUSoXKXXQaB1Golc7jANzARqUQhTjAJppdPp3sS957JdPN/OY/A/+tU3vfpqxS1UkUdXVVnccRWGsVxx7QeIzhRhs4u4w+nbWqLr6DooOXclgDRpMAvDLWN4OtozQGwSK0Kft08Jn5iO9uF54dc0sHdw4yV8OXRWINgDLoHofc7k/qA1gWPWE9XcZ1AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `9e.png`: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABB0lEQVR4nGNgoD9gROHJuHubSN+c+k191TkMlXozn317cuLuxw+vJqNLMSlMffNguqOc/5k/bwrRJU2XvblbLccuWfXpx1klNDmvLe/PZMswMtic/fM4iQVVzm3H+xt5EkxMEsUfX3QJo8pxzH57I0+Skdtj/tXXizWggjD9HGo883aJe2kb63Pf3HIbTfL/3/+GxWLKQizMfx4d+osm+X29hK3Jw4v3pJzZzj9nQJP8tfKLwo+Hlz+F+7y6hhE4UCA/8e9BY0SwoEp++/L//R1ckl8/I/PQJGUU8UiysiNHIprks3v/mFhwSb6/8ZhPmQWHJMOF7SopKgw4AKvvuadtnLhk6QAAMz1emdEzFPAAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `9f.png`: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqUlEQVR4nMXQIQoCQRTG8Y91wWRxj6AIRoPRqxi9g1jsgpewmASrwRNocW0TxWjZtEHmb1iQ1X0zUV8ZHj/mm/dG+nNl2xv3oW0XAJhatgQK5wEDoZSUwappA+hIGkG7iWUV56FlpS6qw3gyha6kCTybmEA+2wGMjWFdtSWFYdIZuMLaREmamz/wHvkRtB70g3iKpx7qbfLFmxi6WOy+3qYfmB99+OZv6gW1elq/Pv0SkAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `9g.png`: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUUlEQVR4nGNgGEjwHwGCoEKMcLnnkzjY+RgSV/kIIwSxmUG5HBOG5AUiDcXUiUdSEJ/i/6pEWonfTnwaSdH5n4QgZ8Ijh2bnT9yGCpEbkXQDAHkLHV3QrcYoAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for `user_drawing.png`: 7\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'Custom test inputs'\n",
    "for f in sorted(listdir(input_dir)):\n",
    "    if not isfile(join(input_dir, f)):\n",
    "        continue\n",
    "    with Image.open(join(input_dir, f)) as img:\n",
    "        test_input_nn = get_test_input_from_pil(img)\n",
    "    display(ToPILImage()(test_input_nn))\n",
    "    print(f\"Neural network classification for `{f}`: {cnn_classifier(test_input_nn)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAAA5UlEQVR4nO2WQQ7CMAwEDeLArf4BfgY3eDpP8RPygoprcpioMk4lJO+p1ci72yaEipRKpdJyvZE4gUvr765wPd7dkNzRTZWI4YzgjOCMYzdDN0e3yAy3Hp+014Mb/Dyz8O1QtUk3XrlkNyUyWTlHNyyXu3INiS7sxjuk18bdOAfdQmvqRAYwuhmRyA5p2IBzIiefDzm9NmxwNKdXaCcKkdNOWEc3E9Bpv1PNzDm6Q/7mPFDMwZnJ/6kQCe03dOMcQZLrxmfi5BspkoPEkVhqzuRJHcmHnF+Yw2QnM3kiUSSlUqmUpy+FT1bMOWUBhAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAACEUlEQVR4nO2WMW7bQBBF/1IEyE5s7MpAeAS3qawq18gVXLm0hRwgdUrfIK278B5JAJZGqgUSwAS84LggRe7Ozg+ULgU/IFHk4/87HKyWC2zatOk/1OX3B0K+iXQmcCLSL2dFRAoAjUmuaAEiIt7y7NL7IlICQG2R9aImjfy4tQu4CdMn9xz+pOdR0T3wTgyPwyMAyQzAbgCwtzzlMwDgmHv2HYDK8jQdgLB6VtIeAYxW0fcAsLPSxunLSPsE2I/jAgA4I+30I08rodIWMrXfGeNUdJx6TjOqpml7mnaSkRZU1Wuap2mepvU07ajSFlWYSJ72CpYG0NpAa9NpZ3Q0G0fLqPof0njV2TjM85e0kREx1wMAcAMjhfkTAEpzrQKAmqY1nhHfU0/HSAumaPXn80DJXF20J01zlBQjIwiMlAMjtWek6ek4HSMtGOFir9O0bUmaoyRuge4BIwX1xG1TaZ6Rumckmm1KN0k58cmBWdI5xXsdE0c9SQvOTEuak3o8I0lzEpI257wKWnrXeXMqTaPEBUaU+IIW78UGRuK/ooroGWnoOI+dVSKSDY3ylJTUIyPXgZFD+qCrXLQZni4spYXPvz6Mv99flMqCSj6KiEi+ku5fZFJWQTO/RXLSzscxI4f5qJ4K07Y72Xpn8yAjy3P1mhQYvw5Pdz/jlXRSJc/qyskT5EtW1DyOJ2DTpk2b8AZiEKY/t4E4xwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAABwklEQVR4nO2WPY4TQRCFv55dMQ4QngBiT8gRyLw5CTEn4Awk9mVIiLgA2jnCimgjNAfYwAFiLbBcBPbMdu3UswxISEj9orY+v6rqv+qBoqKiot/Qs/vPgqzMupiYWZ/9rMbRBdCE5DkwC8k74DLKUpmZ7SPPC4AUkZdxwZDMvt5f23pKatvBwgLP3LZQ554hT8Mt7LiaktY+iQpWd0ByC3fUYZltM4mWrMNPdNDF7uDMog0VfBtKfEz2NwCsp3mO+9xlHq/l1HNUL0k7rWDwoEgrowXz+dfRJGGD0EJWcKI2nadRpJcenafvFaFT9Sx1bZIsxb9IO+WpJHm6VeTNRuVxXSz3JDXR2lw7yDyvUOTKh8gurYleRcIvdeVGbUguUR12huqwDb7DPpANvdjH+q6yqCcCsIp6InDi5LBQjwnzqIsBsEUp5d3SyzKXPqNeq+zAeU+HIjp4/picW8FcLnZ9Itr6jDyeyJt1wqNJ+Dr/cbS/JV7prF14RLRnr8iT8Oy8//Lx7W14fs3859PoOTSJiBwGXRCsNjN3T0fPDNx0HkgD8CMiLfhLN5Ie4CYjY0ebv/75vfkQlFZUVFRU9L/qF91Tg33y0QWoAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAABr0lEQVR4nO1Wy03DQBR8Dkb4gMAFIGGJQkgnFEARuJT0wSUlcAehpQNfED5YXi55Y+lNJoQoICQ8p43H89m3thyzGTNmzPi3WMgLp5KpWsXUMudWui1p4Rh9kQJRZF900Y3sfbFwTUm3eE4V3UZf1HV0c21DDdA65pQ0Jr8wuCaRBjnU2hcpNhiQHHNKzyG3AbbRbdoPuaEBdUNr6raHm9Q0UqNbp6jBTpvYGtPRE9UNdmhkDj8H0s2+ngFrAMqBW9RMbsfQmNRMO03RDZomanyklFP6a8I50FhgoOmiG06ujm6lU3QKlbvRKfTuRqdQwS1q8NrTTuFGmsqZZIEBqHUvp1PJiQJ82kAXfl9uck5ydOs3iyvc68FVYWZ28fbEbvnjcXy+yzkz40iym25tgcGsV7E1npBV1DhQYPqW+O8mMtnMbHx95wZ23bcv9zfn/AUEHtaiwRY3QGuWyiQfkiOZVt56UM4hmmMyxS/l7MNE4L/SFk37Iw3oXZB37uimmUIye3QjyBx9pgvJ7GitNaNktEYypWTwtWG3XjKdZJJk1vGC40wR3zmvGTP+LD4BEvGTvhqYu2EAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAABg0lEQVR4nO2WMVLDMBREV3EYN0DMBSAFB+AGCcfgJJS44Di0DHSEG9BRQknFuKCAGcdLEbAl+W/G4xRQaCvZz/v/ypY0BpKSkv5Srh1NInJc/o6m3uO3e9k5Ho1CGUlyZVTb2Ffoa0aStBIUAGCSOQA0FlkCQG20AUmyMjyb2VfoK2ueL18aAyCPWkzMYXTZSKI9UKSW1aay2hhPnLpTpqtJEn+ZQam1Z0S2WF41SbRnS7YR1UYRV4pncr5Jsr5XxNuKvQSVJPuSZCapAaC0SAP87OKeFsEG9nVA8tMkuCPN4wAA6a2SIHUhHIAL34+vK0kWcp2eSE/Osh2Hb9SfztC1IwMgkwmcTKD7DCORvAShx3lLZPc+Ts501wTD++xWLfaoan6AeD66miJ6OmOy6T5a2/oocihjP3gbyD+lL06XX9bzs/fw3On6FEcIDsWOzAHg1SJLIPgP6r4Iw8vO4wBgDYNMAODaCp2T/PBvtJ4a9dmNZYFbP5n3k5KSkpKS/r2+AVgTdbCNaLw4AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAAB6klEQVR4nO2WPW7cMBSEh1wByy4s060OkTrWUXIT6yi+RooAyg18BJUpiTShA2Wfi7UovieOYbgIXGgK/eDTPI4k/gGHDh36D+oZcGm98ob4wMiXzKrJTDwOjHhMpNgnqR5SigIiWYjHYbHPvugsAwtw3a51tfibkT4xMsykGdRvozxnSsJfRuIvRr49vCWA8jhK/JWRbmEkZEbiI4t2p+78m4iKpqT7QOVxlPjMSJdogpmRMLFoF31beXpK9CeoZTr75nGUIDPiEyMdGAkzI3ECkX2dzWPH+0a+smK78V489hNsxNuJrRDzrytiX7TKNjESB0Z66ym6P4m04Z3INu+qagOAz02PiOhyq8fdYrSqAQBig9zOoUG66qhJ2NVer2OVQ5MeP13d/qb7DJxExr1nBPBPPftCXNWYJoIMIGNoVAvYdywAwCUDcPV/sKsmJXFPEvXEW0JejZKRkukd1T40Se/wzA2y2+dso/71agNvZ2JkbHgSTRB3CVZdMvDKnsJR0mwndYBeUVVP9EuD8GrwALrcIjyBAxBS0zO2RzBuf2Bukt6sqCvJiMAwNZKcRP78aG45TyIizZ3QtRwsEcDMISXbCNPnCplgJoVCHmG3G6vOIjp08Sx2Tiwz9FWevjeLHTp06NBH1jM++H8YjbW7cAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAABaElEQVR4nO2VMU7EMBBFx1YkUoFvkNQcguQKnIM7sHAFJO6THmhp10dwaa2iDA1Z2c4+tKT2b2Lv8/+exMmsSFVVVVXVKrMObr6+jx/D52u/WXKnelTVsDV3qqqq8fyDXQeblDMZsRSlNLNZaovr1rOIzLDP6f3x/u0p2adQd+F+sIJfBfa0RNwOz4U7XSvA2lwgEjx6JiK9kAasYBDSgh4kZiZiYSy4SqSJRNjTBiLO/z8tfaKWQEH8jn36iciICQdMYyUHV3gWAZnrPBmxM5ElEuFJE4i0QsQ5IunHmJPeC6hLSXHamIa1jRPtM6TkSs+BgOjLDg+SZyTZq5NWbZDk/Z97QzaLRBr2BCKtI5K05DLNE+mFlL06uQeJn7CCEdMyTyo+7IdsZpGkyvtE4jFILJ7pwp6ZSIOnPe/wZB0kIxHT/vAgaSORIu6qfwyHhD2B07i2gMQjmaiYjoDcImmQVFVVVYF+AKNGZw3wEs7NAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAACPklEQVR4nO2WMY7VMBCGfydPSgqkTUmX3AA6yuRInICXG3AZOooNt6BBuFiJhiI0KELZ/BRO8uz49y4gyvxFkqfPnhnbM+MHnDp16qjr4+dPnAQw5CO5bD+zG8mADDCCXNyrj0npXl1MKvdqYtIgkEc6pETynqSNgCE/1posQN4bQXK3+utGbhFcDiMzpPRHZEmSLEn+q5856eeJlf5D1PP6tn/jJ0nm5JjCxcYhtmbCkbEfMWfP6MiP80BlrUmQ2aX8YfcAwHAGYPZl3eZk7luQBaYDMlXBpAWKUcTWowJKRQa8wO14fGKRA9Ug/BRkj1YA5OQD3iliSHb6/K7kD7UcoCU5SnIXVLZ/ChO85UQhaGtoKVsigNpriaEuJDXBK7LXpPDCDjPx5d4Zj7r/mgjO8D31lhbMZScHSi6ykwOvF8pOjryb0ckWXNCiVjWHEhbjsaEDAOoFyPdNCOrnp18kPum+C0MA1oIXnRyGgOzkW4lWMcl+BSb8e25KkRIpgjFFnOthjMmauSK2vUtFcoXY2nhO57sL5LagjiNYU6NRsYXKjl+2isiqJp6zSfhh0tpznfyJqIW11U9sbTEpa9uXsIaUtbWmhLUt1ysclSfP53lrscxqbUhaGxDJVfXe5P0MCUcHdbo/jtZsEOIx34wgdPsibkD0JVI34ATgzqo5FwBvFUHON1/6QVhrSb/HB3cjvKs+ygPZxUbA/wfjkWl/HMm8T5R+bByzu+a8WyHI+G/zBzXl1KlTp06l9Rs999jLuzLurgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=1 size=200x200>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADIAQAAAACFI5MzAAABkklEQVR4nO2WPU7DQBBGn2ND3JGSDpfcAl+AM3AGJEqKHILrINxxDCiRQCIFSJZwPBSg2GPmiyIrFAhP5fXbb352vLuGySab7B9bUvcGWe95fp0N537byX0ryN2riSj2YMtuOOseD3nsT+yRUyrK0Ju1Zj1Vp0nx8TuS0QiSUwuy4EiQ4j0RpHwRK4AtcVlvLFlDXM/sA5ZhnOwJqpDk4FdtQxYoTSE1pdT4tjlSIHs6EA5IJcgq9ObycqSUBKDur2m/2+Sxxr3+4c1CMoemDQm31gzq/rIzM7NQ8zic6vWhZjWcF8b0pJbeGultDbzFlR5X3Mioc7E6et0gk/WM0cSVAv6o+MUMtEZ3LlNnL6nOYL+Vas2I3HQXtnROZjCqC9KbXjfdny3eJGFMTxNFiE8kAH9r9eNIjfoJgFTc6INyZnKwYwbuDtwxDiOIurghGZHbmAw0MUkSSfabwT5JIcnF85WQm1n8vclvmtTM4s5lqF2So06kBX5z+0rrkKzwPy/dZqrby/MDkfdkk0022d+zT/XuegMN48wPAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network classification for drawing: 9\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "\n",
    "width = 200  # canvas width\n",
    "height = 200 # canvas height\n",
    "center = height//2\n",
    "white = (255, 255, 255) # canvas back\n",
    "\n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    canvas.create_oval(x1, y1, x2, y2, fill='white',width=10)\n",
    "    draw.line([x1, y1, x2, y2],fill='white',width=10)\n",
    "\n",
    "master = Tk()\n",
    "\n",
    "# create a tkinter canvas to draw on\n",
    "canvas = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas.pack()\n",
    "\n",
    "# create an empty PIL image and draw object to draw on\n",
    "img = PIL.Image.new(\"1\", (width, height))\n",
    "draw = ImageDraw.Draw(img)\n",
    "canvas.pack(expand=YES, fill=BOTH)\n",
    "canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "def clear():\n",
    "    draw.rectangle((0, 0, width, height), width=0, fill='black')\n",
    "    canvas.delete('all')\n",
    "\n",
    "def save():\n",
    "    filename = \"Custom test inputs/user_drawing.png\"\n",
    "    img.save(filename)\n",
    "    test_input_nn = get_test_input_from_pil(img)\n",
    "    display(img)\n",
    "    print(f\"Neural network classification for drawing: {cnn_classifier(test_input_nn)}\")\n",
    "    clear()\n",
    "\n",
    "# add a button to save the image\n",
    "button=Button(text=\"save\", command=save)\n",
    "button.pack()\n",
    "\n",
    "master.mainloop()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
